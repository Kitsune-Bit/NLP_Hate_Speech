{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.stem.porter import * \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import *\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp;amp; as a man you should always take the trash out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &amp;#57361;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                                                                                                                          tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...  \n",
       "1                                                         !!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!  \n",
       "2                      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit  \n",
       "3                                                                                !!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny  \n",
       "4     !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./twitter_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    24163\n",
       "1    19190\n",
       "0     1430\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions = r'@[A-Za-z0-9]+'\n",
    "hashes = r'#[A-Za-z0-9]+'\n",
    "amps = r'&[A-Za-z0-9]+'\n",
    "url_links = r'https?://[A-Za-z0-9./]+'\n",
    "picture_url = r'pic.twitter.com/[A-Za-z0-9./]+'\n",
    "www_link = r'www.[^ ]+'\n",
    "comb = r'|'.join((mentions, url_links, picture_url, www_link, hashes, amps))\n",
    "negations_dic = {\"isn't\":\"isnot\", \"aren't\":\"arenot\", \"wasn't\":\"wasnot\", \"weren't\":\"werenot\",\n",
    "                \"haven't\":\"havenot\",\"hasn't\":\"hasnot\",\"hadn't\":\"hadnot\",\"won't\":\"willnot\",\n",
    "                \"wouldn't\":\"wouldnot\", \"don't\":\"donot\", \"doesn't\":\"doesnot\",\"didn't\":\"didnot\",\n",
    "                \"can't\":\"cannot\",\"couldn't\":\"couldnot\",\"shouldn't\":\"shouldnot\",\"mightn't\":\"mightnot\",\n",
    "                \"mustn't\":\"mustnot\",\n",
    "                \"is not\":\"isnot\", \"are not\":\"arenot\", \"was not\":\"wasnot\", \"were not\":\"werenot\",\n",
    "                \"have not\":\"havenot\",\"has not\":\"hasnot\",\"had not\":\"hadnot\",\"will not\":\"willnot\",\n",
    "                \"would not\":\"wouldnot\", \"do not\":\"donot\", \"does not\":\"doesnot\",\"did not\":\"didnot\",\n",
    "                \"can not\":\"cannot\",\"could not\":\"couldnot\",\"should not\":\"shouldnot\",\"might not\":\"mightnot\",\n",
    "                \"must not\":\"mustnot\"}\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "\n",
    "def tweet_cleaner(text):\n",
    "    cleaned = re.sub(comb, '', text)\n",
    "    try:\n",
    "        decoded = cleaned.decode('utf-8-sig')\n",
    "    except:\n",
    "        decoded = cleaned\n",
    "    \n",
    "    lower_case = decoded.lower()\n",
    "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case)\n",
    "    letters_only = re.sub('[^a-zA-Z]', ' ', neg_handled)\n",
    "    no_extra_white_space = re.sub('\\s+', ' ', letters_only)\n",
    "    return no_extra_white_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 44783/44783 [00:01<00:00, 33764.08it/s]\n"
     ]
    }
   ],
   "source": [
    "clean_tweet_texts = []\n",
    "for i in tqdm(range(0,len(df.index))):\n",
    "    clean_tweet_texts.append(tweet_cleaner(str(df['tweet'][i])))\n",
    "\n",
    "clean_df = pd.DataFrame(clean_tweet_texts,columns=['tweet'])\n",
    "df['cleaned_tweet'] = clean_df.tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp;amp; as a man you should always take the trash out...</td>\n",
       "      <td>rt as a woman you shouldnot complain about cleaning up your house as a man you should always take the trash out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!</td>\n",
       "      <td>rt boy dats cold tyga dwn bad for cuffin dat hoe in the st place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit</td>\n",
       "      <td>rt dawg rt you ever fuck a bitch and she start to cry you be confused as shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny</td>\n",
       "      <td>rt g anderson based she look like a tranny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &amp;#57361;</td>\n",
       "      <td>rt the shit you hear about me might be true or it might be faker than the bitch who told it to ya</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  \\\n",
       "0      2   \n",
       "1      1   \n",
       "2      1   \n",
       "3      1   \n",
       "4      1   \n",
       "\n",
       "                                                                                                                                          tweet  \\\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...   \n",
       "1                                                         !!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!   \n",
       "2                      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit   \n",
       "3                                                                                !!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny   \n",
       "4     !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;   \n",
       "\n",
       "                                                                                                       cleaned_tweet  \n",
       "0   rt as a woman you shouldnot complain about cleaning up your house as a man you should always take the trash out   \n",
       "1                                                  rt boy dats cold tyga dwn bad for cuffin dat hoe in the st place   \n",
       "2                                      rt dawg rt you ever fuck a bitch and she start to cry you be confused as shit  \n",
       "3                                                                         rt g anderson based she look like a tranny  \n",
       "4                 rt the shit you hear about me might be true or it might be faker than the bitch who told it to ya   "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['class','tweet','cleaned_tweet']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24163\n",
       "1    20620\n",
       "Name: is_offensive, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_offensive'] = 0\n",
    "df.loc[(df['class'] == 0),'is_offensive']=1\n",
    "df.loc[(df['class'] == 1),'is_offensive']=1\n",
    "df['is_offensive'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>is_offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp;amp; as a man you should always take the trash out...</td>\n",
       "      <td>rt as a woman you shouldnot complain about cleaning up your house as a man you should always take the trash out</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!</td>\n",
       "      <td>rt boy dats cold tyga dwn bad for cuffin dat hoe in the st place</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit</td>\n",
       "      <td>rt dawg rt you ever fuck a bitch and she start to cry you be confused as shit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny</td>\n",
       "      <td>rt g anderson based she look like a tranny</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &amp;#57361;</td>\n",
       "      <td>rt the shit you hear about me might be true or it might be faker than the bitch who told it to ya</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  \\\n",
       "0      2   \n",
       "1      1   \n",
       "2      1   \n",
       "3      1   \n",
       "4      1   \n",
       "\n",
       "                                                                                                                                          tweet  \\\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...   \n",
       "1                                                         !!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!   \n",
       "2                      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit   \n",
       "3                                                                                !!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny   \n",
       "4     !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;   \n",
       "\n",
       "                                                                                                       cleaned_tweet  \\\n",
       "0   rt as a woman you shouldnot complain about cleaning up your house as a man you should always take the trash out    \n",
       "1                                                  rt boy dats cold tyga dwn bad for cuffin dat hoe in the st place    \n",
       "2                                      rt dawg rt you ever fuck a bitch and she start to cry you be confused as shit   \n",
       "3                                                                         rt g anderson based she look like a tranny   \n",
       "4                 rt the shit you hear about me might be true or it might be faker than the bitch who told it to ya    \n",
       "\n",
       "   is_offensive  \n",
       "0             0  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [woman, you, shouldnot, complain, about, cleaning, your, house, man, you, should, always, take, the, trash, out]\n",
       "1                                                [boy, dats, cold, tyga, dwn, bad, for, cuffin, dat, hoe, the, place]\n",
       "2                                           [dawg, you, ever, fuck, bitch, and, she, start, cry, you, confused, shit]\n",
       "3                                                                          [anderson, based, she, look, like, tranny]\n",
       "4                               [the, shit, you, hear, about, might, true, might, faker, than, the, bitch, who, told]\n",
       "Name: cleaned_tweet, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_tweet'] = df['cleaned_tweet'].astype(str)\n",
    "df.cleaned_tweet = df.cleaned_tweet.apply(lambda x: ' '.join([w for w in x.split() if len(w) > 2]))\n",
    "tokenized_tweet = df.cleaned_tweet.apply(lambda x: x.split())\n",
    "tokenized_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [woman, you, shouldnot, complain, about, clean, your, hous, man, you, should, alway, take, the, trash, out]\n",
       "1                                            [boy, dat, cold, tyga, dwn, bad, for, cuffin, dat, hoe, the, place]\n",
       "2                                        [dawg, you, ever, fuck, bitch, and, she, start, cri, you, confus, shit]\n",
       "3                                                                      [anderson, base, she, look, like, tranni]\n",
       "4                          [the, shit, you, hear, about, might, true, might, faker, than, the, bitch, who, told]\n",
       "Name: cleaned_tweet, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = PorterStemmer() \n",
    "tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) #stemming\n",
    "tokenized_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>is_offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp;amp; as a man you should always take the trash out...</td>\n",
       "      <td>woman you shouldnot complain about clean your hous man you should alway take the trash out</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!</td>\n",
       "      <td>boy dat cold tyga dwn bad for cuffin dat hoe the place</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit</td>\n",
       "      <td>dawg you ever fuck bitch and she start cri you confus shit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny</td>\n",
       "      <td>anderson base she look like tranni</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &amp;#57361;</td>\n",
       "      <td>the shit you hear about might true might faker than the bitch who told</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just blows me..claim you so faithful and down for somebody but still fucking with hoes! &amp;#128514;&amp;#128514;&amp;#128514;\"</td>\n",
       "      <td>madison the shit just blow claim you faith and down for somebodi but still fuck with hoe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!\"@__BrighterDays: I can not just sit up and HATE on another bitch .. I got too much shit going on!\"</td>\n",
       "      <td>brighterday cannot just sit and hate anoth bitch got too much shit go</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!&amp;#8220;@selfiequeenbri: cause I'm tired of you big bitches coming for us skinny girls!!&amp;#8221;</td>\n",
       "      <td>caus tire you big bitch come for skinni girl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>\" &amp;amp; you might not get ya bitch back &amp;amp; thats that \"</td>\n",
       "      <td>you mightnot get bitch back that that</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>\" @rhythmixx_ :hobbies include: fighting Mariam\"\\n\\nbitch</td>\n",
       "      <td>hobbi includ fight mariam bitch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  \\\n",
       "0      2   \n",
       "1      1   \n",
       "2      1   \n",
       "3      1   \n",
       "4      1   \n",
       "5      1   \n",
       "6      1   \n",
       "7      1   \n",
       "8      1   \n",
       "9      1   \n",
       "\n",
       "                                                                                                                                                            tweet  \\\n",
       "0                    !!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...   \n",
       "1                                                                           !!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!   \n",
       "2                                        !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit   \n",
       "3                                                                                                  !!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny   \n",
       "4                       !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;   \n",
       "5  !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just blows me..claim you so faithful and down for somebody but still fucking with hoes! &#128514;&#128514;&#128514;\"   \n",
       "6                                                       !!!!!!\"@__BrighterDays: I can not just sit up and HATE on another bitch .. I got too much shit going on!\"   \n",
       "7                                                              !!!!&#8220;@selfiequeenbri: cause I'm tired of you big bitches coming for us skinny girls!!&#8221;   \n",
       "8                                                                                                      \" &amp; you might not get ya bitch back &amp; thats that \"   \n",
       "9                                                                                                       \" @rhythmixx_ :hobbies include: fighting Mariam\"\\n\\nbitch   \n",
       "\n",
       "                                                                                cleaned_tweet  \\\n",
       "0  woman you shouldnot complain about clean your hous man you should alway take the trash out   \n",
       "1                                      boy dat cold tyga dwn bad for cuffin dat hoe the place   \n",
       "2                                  dawg you ever fuck bitch and she start cri you confus shit   \n",
       "3                                                          anderson base she look like tranni   \n",
       "4                      the shit you hear about might true might faker than the bitch who told   \n",
       "5    madison the shit just blow claim you faith and down for somebodi but still fuck with hoe   \n",
       "6                       brighterday cannot just sit and hate anoth bitch got too much shit go   \n",
       "7                                                caus tire you big bitch come for skinni girl   \n",
       "8                                                       you mightnot get bitch back that that   \n",
       "9                                                             hobbi includ fight mariam bitch   \n",
       "\n",
       "   is_offensive  \n",
       "0             0  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  \n",
       "5             1  \n",
       "6             1  \n",
       "7             1  \n",
       "8             1  \n",
       "9             1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(0,len(tokenized_tweet)):\n",
    "    tokenized_tweet[i] = ' '.join(tokenized_tweet[i])    \n",
    "df['cleaned_tweet'] = tokenized_tweet\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [woman, you, shouldnot, complain, about, clean, your, hous, man, you, should, alway, take, the, trash, out]\n",
       "1                                            [boy, dat, cold, tyga, dwn, bad, for, cuffin, dat, hoe, the, place]\n",
       "2                                        [dawg, you, ever, fuck, bitch, and, she, start, cri, you, confus, shit]\n",
       "3                                                                      [anderson, base, she, look, like, tranni]\n",
       "4                          [the, shit, you, hear, about, might, true, might, faker, than, the, bitch, who, told]\n",
       "5     [madison, the, shit, just, blow, claim, you, faith, and, down, for, somebodi, but, still, fuck, with, hoe]\n",
       "6                            [brighterday, cannot, just, sit, and, hate, anoth, bitch, got, too, much, shit, go]\n",
       "7                                                         [caus, tire, you, big, bitch, come, for, skinni, girl]\n",
       "8                                                                  [you, mightnot, get, bitch, back, that, that]\n",
       "9                                                                          [hobbi, includ, fight, mariam, bitch]\n",
       "Name: cleaned_tweet, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tweet = df.cleaned_tweet.apply(lambda x: x.split())\n",
    "tokenized_tweet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44783, 500)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=500, ngram_range=(1,3)) #unigram, bigram, trigram\n",
    "tfidf_df = tfidf_vectorizer.fit_transform(df['cleaned_tweet'])\n",
    "tfidf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9664575, 12832650)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v = gensim.models.Word2Vec(\n",
    "            tokenized_tweet,\n",
    "            size=500, # output dimensions\n",
    "            window=5, # context window size\n",
    "            min_count=5, # ignore any words that appear less than 5 times.                                  \n",
    "            sg = 1, # skip-gram model\n",
    "            hs = 0,\n",
    "            negative = 10, # negative sampling\n",
    "            workers= 12, # number of cores that can be used\n",
    ") \n",
    "\n",
    "model_w2v.train(tokenized_tweet, total_examples= len(df['cleaned_tweet']), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hoe', 0.5027706027030945),\n",
       " ('nomo', 0.4167632460594177),\n",
       " ('yassss', 0.40614134073257446),\n",
       " ('lyin', 0.3896762728691101),\n",
       " ('gbe', 0.3894902467727661),\n",
       " ('trippen', 0.38934704661369324),\n",
       " ('frontin', 0.38013243675231934),\n",
       " ('braceface', 0.3799997568130493),\n",
       " ('wallah', 0.378622829914093),\n",
       " ('lexi', 0.37748393416404724)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar(positive='bitch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += model_w2v[word].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError:  # handling the case where the token is not in vocabulary\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44783, 500)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_arrays = np.zeros((len(tokenized_tweet), 500)) \n",
    "for i in range(len(tokenized_tweet)):\n",
    "    wordvec_arrays[i,:] = word_vector(tokenized_tweet[i], 500)\n",
    "wordvec_df = pd.DataFrame(wordvec_arrays)\n",
    "wordvec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.080567</td>\n",
       "      <td>0.087247</td>\n",
       "      <td>0.009612</td>\n",
       "      <td>-0.272802</td>\n",
       "      <td>0.011458</td>\n",
       "      <td>-0.061806</td>\n",
       "      <td>0.031311</td>\n",
       "      <td>0.092972</td>\n",
       "      <td>0.035659</td>\n",
       "      <td>-0.108299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036406</td>\n",
       "      <td>0.003328</td>\n",
       "      <td>0.093741</td>\n",
       "      <td>0.041980</td>\n",
       "      <td>-0.001982</td>\n",
       "      <td>-0.064888</td>\n",
       "      <td>-0.004784</td>\n",
       "      <td>0.042090</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>-0.152933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.095384</td>\n",
       "      <td>0.111423</td>\n",
       "      <td>-0.018234</td>\n",
       "      <td>-0.343409</td>\n",
       "      <td>0.126451</td>\n",
       "      <td>-0.146284</td>\n",
       "      <td>-0.036135</td>\n",
       "      <td>0.057265</td>\n",
       "      <td>-0.034421</td>\n",
       "      <td>0.077683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046527</td>\n",
       "      <td>0.080112</td>\n",
       "      <td>-0.014584</td>\n",
       "      <td>0.102737</td>\n",
       "      <td>0.034078</td>\n",
       "      <td>0.022953</td>\n",
       "      <td>-0.085681</td>\n",
       "      <td>0.095434</td>\n",
       "      <td>0.037691</td>\n",
       "      <td>-0.041535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.068898</td>\n",
       "      <td>0.098352</td>\n",
       "      <td>0.136356</td>\n",
       "      <td>-0.313098</td>\n",
       "      <td>-0.005599</td>\n",
       "      <td>-0.091508</td>\n",
       "      <td>0.024152</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>-0.078076</td>\n",
       "      <td>-0.050179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054432</td>\n",
       "      <td>0.039867</td>\n",
       "      <td>-0.005000</td>\n",
       "      <td>0.008658</td>\n",
       "      <td>-0.045559</td>\n",
       "      <td>0.007894</td>\n",
       "      <td>0.019463</td>\n",
       "      <td>0.028042</td>\n",
       "      <td>0.052773</td>\n",
       "      <td>-0.139427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.044638</td>\n",
       "      <td>0.204748</td>\n",
       "      <td>0.104734</td>\n",
       "      <td>-0.171101</td>\n",
       "      <td>0.019810</td>\n",
       "      <td>-0.094981</td>\n",
       "      <td>0.043435</td>\n",
       "      <td>0.121041</td>\n",
       "      <td>0.051227</td>\n",
       "      <td>-0.108502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095133</td>\n",
       "      <td>-0.043309</td>\n",
       "      <td>0.039371</td>\n",
       "      <td>-0.041993</td>\n",
       "      <td>-0.167356</td>\n",
       "      <td>0.022635</td>\n",
       "      <td>-0.159386</td>\n",
       "      <td>0.174173</td>\n",
       "      <td>-0.049309</td>\n",
       "      <td>-0.161837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.131282</td>\n",
       "      <td>0.080979</td>\n",
       "      <td>0.100818</td>\n",
       "      <td>-0.346867</td>\n",
       "      <td>-0.047246</td>\n",
       "      <td>-0.053518</td>\n",
       "      <td>-0.016497</td>\n",
       "      <td>0.104746</td>\n",
       "      <td>-0.044078</td>\n",
       "      <td>-0.045439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095786</td>\n",
       "      <td>-0.005286</td>\n",
       "      <td>0.064299</td>\n",
       "      <td>0.049106</td>\n",
       "      <td>0.041619</td>\n",
       "      <td>0.024203</td>\n",
       "      <td>-0.105287</td>\n",
       "      <td>0.053482</td>\n",
       "      <td>0.080163</td>\n",
       "      <td>-0.153004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.080567  0.087247  0.009612 -0.272802  0.011458 -0.061806  0.031311   \n",
       "1 -0.095384  0.111423 -0.018234 -0.343409  0.126451 -0.146284 -0.036135   \n",
       "2 -0.068898  0.098352  0.136356 -0.313098 -0.005599 -0.091508  0.024152   \n",
       "3  0.044638  0.204748  0.104734 -0.171101  0.019810 -0.094981  0.043435   \n",
       "4 -0.131282  0.080979  0.100818 -0.346867 -0.047246 -0.053518 -0.016497   \n",
       "\n",
       "        7         8         9    ...       490       491       492       493  \\\n",
       "0  0.092972  0.035659 -0.108299  ...  0.036406  0.003328  0.093741  0.041980   \n",
       "1  0.057265 -0.034421  0.077683  ...  0.046527  0.080112 -0.014584  0.102737   \n",
       "2  0.003866 -0.078076 -0.050179  ...  0.054432  0.039867 -0.005000  0.008658   \n",
       "3  0.121041  0.051227 -0.108502  ...  0.095133 -0.043309  0.039371 -0.041993   \n",
       "4  0.104746 -0.044078 -0.045439  ...  0.095786 -0.005286  0.064299  0.049106   \n",
       "\n",
       "        494       495       496       497       498       499  \n",
       "0 -0.001982 -0.064888 -0.004784  0.042090  0.058333 -0.152933  \n",
       "1  0.034078  0.022953 -0.085681  0.095434  0.037691 -0.041535  \n",
       "2 -0.045559  0.007894  0.019463  0.028042  0.052773 -0.139427  \n",
       "3 -0.167356  0.022635 -0.159386  0.174173 -0.049309 -0.161837  \n",
       "4  0.041619  0.024203 -0.105287  0.053482  0.080163 -0.153004  \n",
       "\n",
       "[5 rows x 500 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tfidf_df\n",
    "y = df['is_offensive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logistic_regression.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.82886745266167"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "accuracy_percentage = 100 * accuracy\n",
    "accuracy_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9538491945844452"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = wordvec_df\n",
    "y = df['is_offensive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logistic_regression.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.85530546623794"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "accuracy_percentage = 100 * accuracy\n",
    "accuracy_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9436509489336724"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "for w in model_w2v.wv.vocab.keys():\n",
    "    embeddings_index[w] = model_w2v.wv[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['cleaned_tweet']\n",
    "y = df['is_offensive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=100000)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "sequences = tokenizer.texts_to_sequences(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dick call taco bell becaus bitch love their mouth but hate their ass\n",
      "gucci mane jail and drop mixtap everi month and you hoe cannot even text back\n",
      "hate when hoe caption shit who she lol shit hella cheesi\n",
      "true but then again opinion hoe someon who goe and sleep with everybodi\n",
      "afternoon all it far too nice outsid stuck the offic how everyon\n"
     ]
    }
   ],
   "source": [
    "for x in x_train[:5]:\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[182, 79, 1440, 1889, 144, 3, 22, 155, 580, 16, 106, 155, 34],\n",
       " [1485, 1207, 1066, 4, 523, 1799, 177, 487, 4, 2, 7, 70, 101, 318, 64],\n",
       " [106, 32, 7, 2314, 44, 65, 37, 29, 44, 896, 3244],\n",
       " [449, 16, 59, 146, 1486, 7, 221, 65, 460, 4, 160, 9, 425],\n",
       " [786, 14, 91, 491, 49, 112, 379, 801, 1, 662, 46, 176]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = []\n",
    "for x in x_train:\n",
    "    length.append(len(x.split()))\n",
    "max(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,  182,   79, 1440, 1889,  144,\n",
       "           3,   22,  155,  580,   16,  106,  155,   34],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0, 1485, 1207, 1066,    4,  523, 1799,  177,\n",
       "         487,    4,    2,    7,   70,  101,  318,   64],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,  106,   32,    7,\n",
       "        2314,   44,   65,   37,   29,   44,  896, 3244],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,  449,   16,   59,  146, 1486,\n",
       "           7,  221,   65,  460,    4,  160,    9,  425],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,  786,   14,   91,  491,\n",
       "          49,  112,  379,  801,    1,  662,   46,  176]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_seq = pad_sequences(sequences, maxlen=30)\n",
    "x_train_seq[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
    "x_test_seq = pad_sequences(sequences_test, maxlen=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 100000\n",
    "embedding_matrix = np.zeros((num_words, 500))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(embedding_matrix[3] ,embeddings_index.get('bitch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33587 samples, validate on 11196 samples\n",
      "Epoch 1/5\n",
      " - 7s - loss: 0.1227 - accuracy: 0.9586 - val_loss: 0.1051 - val_accuracy: 0.9646\n",
      "Epoch 2/5\n",
      " - 7s - loss: 0.0845 - accuracy: 0.9727 - val_loss: 0.1214 - val_accuracy: 0.9571\n",
      "Epoch 3/5\n",
      " - 7s - loss: 0.0655 - accuracy: 0.9783 - val_loss: 0.0979 - val_accuracy: 0.9718\n",
      "Epoch 4/5\n",
      " - 7s - loss: 0.0477 - accuracy: 0.9838 - val_loss: 0.1096 - val_accuracy: 0.9670\n",
      "Epoch 5/5\n",
      " - 7s - loss: 0.0366 - accuracy: 0.9880 - val_loss: 0.1410 - val_accuracy: 0.9690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x16ff81c2a48>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn = Sequential()\n",
    "e = Embedding(100000, 500, weights=[embedding_matrix], input_length=30, trainable=False)\n",
    "model_cnn.add(e)\n",
    "model_cnn.add(Conv1D(filters=150, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "model_cnn.add(GlobalMaxPooling1D())\n",
    "model_cnn.add(Dense(200, activation='relu'))\n",
    "model_cnn.add(BatchNormalization())\n",
    "model_cnn.add(Dense(1, activation='sigmoid'))\n",
    "model_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_cnn.fit(x_train_seq, y_train, validation_data=(x_test_seq, y_test), epochs=5,  verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_cnn.predict(x_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(y_pred)):\n",
    "    if (y_pred[i] >= 0.5) :\n",
    "        y_pred[i] = 1\n",
    "    else :\n",
    "        y_pred[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.9006788138621"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "accuracy_percentage = 100 * accuracy\n",
    "accuracy_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9660768403558511"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>is_offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp;amp; as a man you should always take the trash out...</td>\n",
       "      <td>woman you shouldnot complain about clean your hous man you should alway take the trash out</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!</td>\n",
       "      <td>boy dat cold tyga dwn bad for cuffin dat hoe the place</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit</td>\n",
       "      <td>dawg you ever fuck bitch and she start cri you confus shit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny</td>\n",
       "      <td>anderson base she look like tranni</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &amp;#57361;</td>\n",
       "      <td>the shit you hear about might true might faker than the bitch who told</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  \\\n",
       "0      2   \n",
       "1      1   \n",
       "2      1   \n",
       "3      1   \n",
       "4      1   \n",
       "\n",
       "                                                                                                                                          tweet  \\\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...   \n",
       "1                                                         !!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!   \n",
       "2                      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit   \n",
       "3                                                                                !!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny   \n",
       "4     !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;   \n",
       "\n",
       "                                                                                cleaned_tweet  \\\n",
       "0  woman you shouldnot complain about clean your hous man you should alway take the trash out   \n",
       "1                                      boy dat cold tyga dwn bad for cuffin dat hoe the place   \n",
       "2                                  dawg you ever fuck bitch and she start cri you confus shit   \n",
       "3                                                          anderson base she look like tranni   \n",
       "4                      the shit you hear about might true might faker than the bitch who told   \n",
       "\n",
       "   is_offensive  \n",
       "0             0  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    24163\n",
       "1    19190\n",
       "0     1430\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_hate_speech'] = 0\n",
    "df.loc[(df['class'] == 0),'is_hate_speech']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    19190\n",
       "0     1430\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = df[(df['class']==2)].index\n",
    "dfo = df.copy()\n",
    "dfo.drop(index, inplace = True)\n",
    "df = dfo\n",
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19190\n",
       "1     1430\n",
       "Name: is_hate_speech, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_hate_speech'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>is_offensive</th>\n",
       "      <th>is_hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!</td>\n",
       "      <td>boy dat cold tyga dwn bad for cuffin dat hoe the place</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit</td>\n",
       "      <td>dawg you ever fuck bitch and she start cri you confus shit</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny</td>\n",
       "      <td>anderson base she look like tranni</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &amp;#57361;</td>\n",
       "      <td>the shit you hear about might true might faker than the bitch who told</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just blows me..claim you so faithful and down for somebody but still fucking with hoes! &amp;#128514;&amp;#128514;&amp;#128514;\"</td>\n",
       "      <td>madison the shit just blow claim you faith and down for somebodi but still fuck with hoe</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  \\\n",
       "0      1   \n",
       "1      1   \n",
       "2      1   \n",
       "3      1   \n",
       "4      1   \n",
       "\n",
       "                                                                                                                                                            tweet  \\\n",
       "0                                                                           !!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!   \n",
       "1                                        !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit   \n",
       "2                                                                                                  !!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny   \n",
       "3                       !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;   \n",
       "4  !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just blows me..claim you so faithful and down for somebody but still fucking with hoes! &#128514;&#128514;&#128514;\"   \n",
       "\n",
       "                                                                              cleaned_tweet  \\\n",
       "0                                    boy dat cold tyga dwn bad for cuffin dat hoe the place   \n",
       "1                                dawg you ever fuck bitch and she start cri you confus shit   \n",
       "2                                                        anderson base she look like tranni   \n",
       "3                    the shit you hear about might true might faker than the bitch who told   \n",
       "4  madison the shit just blow claim you faith and down for somebodi but still fuck with hoe   \n",
       "\n",
       "   is_offensive  is_hate_speech  \n",
       "0             1               0  \n",
       "1             1               0  \n",
       "2             1               0  \n",
       "3             1               0  \n",
       "4             1               0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           [boy, dat, cold, tyga, dwn, bad, for, cuffin, dat, hoe, the, place]\n",
       "1                                       [dawg, you, ever, fuck, bitch, and, she, start, cri, you, confus, shit]\n",
       "2                                                                     [anderson, base, she, look, like, tranni]\n",
       "3                         [the, shit, you, hear, about, might, true, might, faker, than, the, bitch, who, told]\n",
       "4    [madison, the, shit, just, blow, claim, you, faith, and, down, for, somebodi, but, still, fuck, with, hoe]\n",
       "Name: cleaned_tweet, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tweet = df.cleaned_tweet.apply(lambda x: x.split())\n",
    "tokenized_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20620, 500)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=500, ngram_range=(1,3))\n",
    "tfidf_df = tfidf_vectorizer.fit_transform(df['cleaned_tweet'])\n",
    "tfidf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20620, 500)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_arrays = np.zeros((len(tokenized_tweet), 500)) \n",
    "for i in range(len(tokenized_tweet)):\n",
    "    wordvec_arrays[i,:] = word_vector(tokenized_tweet[i], 500)\n",
    "wordvec_df = pd.DataFrame(wordvec_arrays)\n",
    "wordvec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tfidf_df\n",
    "y = df['is_hate_speech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logistic_regression.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.50145489815714"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "accuracy_percentage = 100 * accuracy\n",
    "accuracy_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5930232558139535"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1452991452991453"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23340961098398172"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = wordvec_df\n",
    "y = df['is_hate_speech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logistic_regression.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.02521823472357"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "accuracy_percentage = 100 * accuracy\n",
    "accuracy_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5299145299145299"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19682539682539682"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28703703703703703"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['cleaned_tweet']\n",
    "y = df['is_offensive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=100000)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "sequences = tokenizer.texts_to_sequences(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = []\n",
    "for x in x_train:\n",
    "    length.append(len(x.split()))\n",
    "max(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_seq = pad_sequences(sequences, maxlen=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
    "x_test_seq = pad_sequences(sequences_test, maxlen=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15465 samples, validate on 5155 samples\n",
      "Epoch 1/5\n",
      " - 3s - loss: 0.0903 - accuracy: 0.9785 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 6.5491e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      " - 3s - loss: 4.5921e-04 - accuracy: 1.0000 - val_loss: 2.9900e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      " - 3s - loss: 2.2123e-04 - accuracy: 1.0000 - val_loss: 1.5901e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      " - 3s - loss: 1.2577e-04 - accuracy: 1.0000 - val_loss: 1.0510e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x16ff7bc4f88>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn2 = Sequential()\n",
    "e = Embedding(100000, 500, weights=[embedding_matrix], input_length=30, trainable=False)\n",
    "model_cnn2.add(e)\n",
    "model_cnn2.add(Conv1D(filters=150, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "model_cnn2.add(GlobalMaxPooling1D())\n",
    "model_cnn2.add(Dense(200, activation='relu'))\n",
    "model_cnn2.add(BatchNormalization())\n",
    "model_cnn2.add(Dense(1, activation='sigmoid'))\n",
    "model_cnn2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_cnn2.fit(x_train_seq, y_train, validation_data=(x_test_seq, y_test), epochs=5,  verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_cnn.predict(x_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(y_pred)):\n",
    "    if (y_pred[i] >= 0.5) :\n",
    "        y_pred[i] = 1\n",
    "    else :\n",
    "        y_pred[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.02230843840931"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "accuracy_percentage = 100 * accuracy\n",
    "accuracy_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4702230843840931"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6396622245678849"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
