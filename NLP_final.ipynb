{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.stem.porter import * \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import *\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp;amp; as a man you should always take the trash out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &amp;#57361;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                                                                                                                          tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...  \n",
       "1                                                         !!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!  \n",
       "2                      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit  \n",
       "3                                                                                !!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny  \n",
       "4     !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./twitter_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    24163\n",
       "1    19190\n",
       "0     1430\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions = r'@[A-Za-z0-9]+'\n",
    "hashes = r'#[A-Za-z0-9]+'\n",
    "amps = r'&[A-Za-z0-9]+'\n",
    "url_links = r'https?://[A-Za-z0-9./]+'\n",
    "picture_url = r'pic.twitter.com/[A-Za-z0-9./]+'\n",
    "www_link = r'www.[^ ]+'\n",
    "comb = r'|'.join((mentions, url_links, picture_url, www_link, hashes, amps))\n",
    "negations_dic = {\"isn't\":\"isnot\", \"aren't\":\"arenot\", \"wasn't\":\"wasnot\", \"weren't\":\"werenot\",\n",
    "                \"haven't\":\"havenot\",\"hasn't\":\"hasnot\",\"hadn't\":\"hadnot\",\"won't\":\"willnot\",\n",
    "                \"wouldn't\":\"wouldnot\", \"don't\":\"donot\", \"doesn't\":\"doesnot\",\"didn't\":\"didnot\",\n",
    "                \"can't\":\"cannot\",\"couldn't\":\"couldnot\",\"shouldn't\":\"shouldnot\",\"mightn't\":\"mightnot\",\n",
    "                \"mustn't\":\"mustnot\",\n",
    "                \"is not\":\"isnot\", \"are not\":\"arenot\", \"was not\":\"wasnot\", \"were not\":\"werenot\",\n",
    "                \"have not\":\"havenot\",\"has not\":\"hasnot\",\"had not\":\"hadnot\",\"will not\":\"willnot\",\n",
    "                \"would not\":\"wouldnot\", \"do not\":\"donot\", \"does not\":\"doesnot\",\"did not\":\"didnot\",\n",
    "                \"can not\":\"cannot\",\"could not\":\"couldnot\",\"should not\":\"shouldnot\",\"might not\":\"mightnot\",\n",
    "                \"must not\":\"mustnot\"}\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "\n",
    "def tweet_cleaner(text):\n",
    "    cleaned = re.sub(comb, '', text)\n",
    "    try:\n",
    "        decoded = cleaned.decode('utf-8-sig')\n",
    "    except:\n",
    "        decoded = cleaned\n",
    "    \n",
    "    lower_case = decoded.lower()\n",
    "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case)\n",
    "    letters_only = re.sub('[^a-zA-Z]', ' ', neg_handled)\n",
    "    no_extra_white_space = re.sub('\\s+', ' ', letters_only)\n",
    "    return no_extra_white_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 44783/44783 [00:01<00:00, 33632.59it/s]\n"
     ]
    }
   ],
   "source": [
    "clean_tweet_texts = []\n",
    "for i in tqdm(range(0,len(df.index))):\n",
    "    clean_tweet_texts.append(tweet_cleaner(str(df['tweet'][i])))\n",
    "\n",
    "clean_df = pd.DataFrame(clean_tweet_texts,columns=['tweet'])\n",
    "df['cleaned_tweet'] = clean_df.tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp;amp; as a man you should always take the trash out...</td>\n",
       "      <td>rt as a woman you shouldnot complain about cleaning up your house as a man you should always take the trash out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!</td>\n",
       "      <td>rt boy dats cold tyga dwn bad for cuffin dat hoe in the st place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit</td>\n",
       "      <td>rt dawg rt you ever fuck a bitch and she start to cry you be confused as shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny</td>\n",
       "      <td>rt g anderson based she look like a tranny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &amp;#57361;</td>\n",
       "      <td>rt the shit you hear about me might be true or it might be faker than the bitch who told it to ya</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  \\\n",
       "0      2   \n",
       "1      1   \n",
       "2      1   \n",
       "3      1   \n",
       "4      1   \n",
       "\n",
       "                                                                                                                                          tweet  \\\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...   \n",
       "1                                                         !!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!   \n",
       "2                      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit   \n",
       "3                                                                                !!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny   \n",
       "4     !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;   \n",
       "\n",
       "                                                                                                       cleaned_tweet  \n",
       "0   rt as a woman you shouldnot complain about cleaning up your house as a man you should always take the trash out   \n",
       "1                                                  rt boy dats cold tyga dwn bad for cuffin dat hoe in the st place   \n",
       "2                                      rt dawg rt you ever fuck a bitch and she start to cry you be confused as shit  \n",
       "3                                                                         rt g anderson based she look like a tranny  \n",
       "4                 rt the shit you hear about me might be true or it might be faker than the bitch who told it to ya   "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['class','tweet','cleaned_tweet']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24163\n",
       "1    20620\n",
       "Name: is_offensive, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_offensive'] = 0\n",
    "df.loc[(df['class'] == 0),'is_offensive']=1\n",
    "df.loc[(df['class'] == 1),'is_offensive']=1\n",
    "df['is_offensive'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>is_offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp;amp; as a man you should always take the trash out...</td>\n",
       "      <td>rt as a woman you shouldnot complain about cleaning up your house as a man you should always take the trash out</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!</td>\n",
       "      <td>rt boy dats cold tyga dwn bad for cuffin dat hoe in the st place</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit</td>\n",
       "      <td>rt dawg rt you ever fuck a bitch and she start to cry you be confused as shit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny</td>\n",
       "      <td>rt g anderson based she look like a tranny</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &amp;#57361;</td>\n",
       "      <td>rt the shit you hear about me might be true or it might be faker than the bitch who told it to ya</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  \\\n",
       "0      2   \n",
       "1      1   \n",
       "2      1   \n",
       "3      1   \n",
       "4      1   \n",
       "\n",
       "                                                                                                                                          tweet  \\\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...   \n",
       "1                                                         !!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!   \n",
       "2                      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit   \n",
       "3                                                                                !!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny   \n",
       "4     !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;   \n",
       "\n",
       "                                                                                                       cleaned_tweet  \\\n",
       "0   rt as a woman you shouldnot complain about cleaning up your house as a man you should always take the trash out    \n",
       "1                                                  rt boy dats cold tyga dwn bad for cuffin dat hoe in the st place    \n",
       "2                                      rt dawg rt you ever fuck a bitch and she start to cry you be confused as shit   \n",
       "3                                                                         rt g anderson based she look like a tranny   \n",
       "4                 rt the shit you hear about me might be true or it might be faker than the bitch who told it to ya    \n",
       "\n",
       "   is_offensive  \n",
       "0             0  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [woman, you, shouldnot, complain, about, cleaning, your, house, man, you, should, always, take, the, trash, out]\n",
       "1                                                [boy, dats, cold, tyga, dwn, bad, for, cuffin, dat, hoe, the, place]\n",
       "2                                           [dawg, you, ever, fuck, bitch, and, she, start, cry, you, confused, shit]\n",
       "3                                                                          [anderson, based, she, look, like, tranny]\n",
       "4                               [the, shit, you, hear, about, might, true, might, faker, than, the, bitch, who, told]\n",
       "Name: cleaned_tweet, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_tweet'] = df['cleaned_tweet'].astype(str)\n",
    "df.cleaned_tweet = df.cleaned_tweet.apply(lambda x: ' '.join([w for w in x.split() if len(w) > 2]))\n",
    "tokenized_tweet = df.cleaned_tweet.apply(lambda x: x.split())\n",
    "tokenized_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [woman, you, shouldnot, complain, about, clean, your, hous, man, you, should, alway, take, the, trash, out]\n",
       "1                                            [boy, dat, cold, tyga, dwn, bad, for, cuffin, dat, hoe, the, place]\n",
       "2                                        [dawg, you, ever, fuck, bitch, and, she, start, cri, you, confus, shit]\n",
       "3                                                                      [anderson, base, she, look, like, tranni]\n",
       "4                          [the, shit, you, hear, about, might, true, might, faker, than, the, bitch, who, told]\n",
       "Name: cleaned_tweet, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = PorterStemmer() \n",
    "tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) #stemming\n",
    "tokenized_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>is_offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp;amp; as a man you should always take the trash out...</td>\n",
       "      <td>woman you shouldnot complain about clean your hous man you should alway take the trash out</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!</td>\n",
       "      <td>boy dat cold tyga dwn bad for cuffin dat hoe the place</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit</td>\n",
       "      <td>dawg you ever fuck bitch and she start cri you confus shit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny</td>\n",
       "      <td>anderson base she look like tranni</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &amp;#57361;</td>\n",
       "      <td>the shit you hear about might true might faker than the bitch who told</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just blows me..claim you so faithful and down for somebody but still fucking with hoes! &amp;#128514;&amp;#128514;&amp;#128514;\"</td>\n",
       "      <td>madison the shit just blow claim you faith and down for somebodi but still fuck with hoe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!\"@__BrighterDays: I can not just sit up and HATE on another bitch .. I got too much shit going on!\"</td>\n",
       "      <td>brighterday cannot just sit and hate anoth bitch got too much shit go</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!&amp;#8220;@selfiequeenbri: cause I'm tired of you big bitches coming for us skinny girls!!&amp;#8221;</td>\n",
       "      <td>caus tire you big bitch come for skinni girl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>\" &amp;amp; you might not get ya bitch back &amp;amp; thats that \"</td>\n",
       "      <td>you mightnot get bitch back that that</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>\" @rhythmixx_ :hobbies include: fighting Mariam\"\\n\\nbitch</td>\n",
       "      <td>hobbi includ fight mariam bitch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  \\\n",
       "0      2   \n",
       "1      1   \n",
       "2      1   \n",
       "3      1   \n",
       "4      1   \n",
       "5      1   \n",
       "6      1   \n",
       "7      1   \n",
       "8      1   \n",
       "9      1   \n",
       "\n",
       "                                                                                                                                                            tweet  \\\n",
       "0                    !!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...   \n",
       "1                                                                           !!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!   \n",
       "2                                        !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit   \n",
       "3                                                                                                  !!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny   \n",
       "4                       !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;   \n",
       "5  !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just blows me..claim you so faithful and down for somebody but still fucking with hoes! &#128514;&#128514;&#128514;\"   \n",
       "6                                                       !!!!!!\"@__BrighterDays: I can not just sit up and HATE on another bitch .. I got too much shit going on!\"   \n",
       "7                                                              !!!!&#8220;@selfiequeenbri: cause I'm tired of you big bitches coming for us skinny girls!!&#8221;   \n",
       "8                                                                                                      \" &amp; you might not get ya bitch back &amp; thats that \"   \n",
       "9                                                                                                       \" @rhythmixx_ :hobbies include: fighting Mariam\"\\n\\nbitch   \n",
       "\n",
       "                                                                                cleaned_tweet  \\\n",
       "0  woman you shouldnot complain about clean your hous man you should alway take the trash out   \n",
       "1                                      boy dat cold tyga dwn bad for cuffin dat hoe the place   \n",
       "2                                  dawg you ever fuck bitch and she start cri you confus shit   \n",
       "3                                                          anderson base she look like tranni   \n",
       "4                      the shit you hear about might true might faker than the bitch who told   \n",
       "5    madison the shit just blow claim you faith and down for somebodi but still fuck with hoe   \n",
       "6                       brighterday cannot just sit and hate anoth bitch got too much shit go   \n",
       "7                                                caus tire you big bitch come for skinni girl   \n",
       "8                                                       you mightnot get bitch back that that   \n",
       "9                                                             hobbi includ fight mariam bitch   \n",
       "\n",
       "   is_offensive  \n",
       "0             0  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  \n",
       "5             1  \n",
       "6             1  \n",
       "7             1  \n",
       "8             1  \n",
       "9             1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(0,len(tokenized_tweet)):\n",
    "    tokenized_tweet[i] = ' '.join(tokenized_tweet[i])    \n",
    "df['cleaned_tweet'] = tokenized_tweet\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [woman, you, shouldnot, complain, about, clean, your, hous, man, you, should, alway, take, the, trash, out]\n",
       "1                                            [boy, dat, cold, tyga, dwn, bad, for, cuffin, dat, hoe, the, place]\n",
       "2                                        [dawg, you, ever, fuck, bitch, and, she, start, cri, you, confus, shit]\n",
       "3                                                                      [anderson, base, she, look, like, tranni]\n",
       "4                          [the, shit, you, hear, about, might, true, might, faker, than, the, bitch, who, told]\n",
       "5     [madison, the, shit, just, blow, claim, you, faith, and, down, for, somebodi, but, still, fuck, with, hoe]\n",
       "6                            [brighterday, cannot, just, sit, and, hate, anoth, bitch, got, too, much, shit, go]\n",
       "7                                                         [caus, tire, you, big, bitch, come, for, skinni, girl]\n",
       "8                                                                  [you, mightnot, get, bitch, back, that, that]\n",
       "9                                                                          [hobbi, includ, fight, mariam, bitch]\n",
       "Name: cleaned_tweet, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tweet = df.cleaned_tweet.apply(lambda x: x.split())\n",
    "tokenized_tweet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44783, 500)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=500, ngram_range=(1,3)) #unigram, bigram, trigram\n",
    "tfidf_df = tfidf_vectorizer.fit_transform(df['cleaned_tweet'])\n",
    "tfidf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9663857, 12832650)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v = gensim.models.Word2Vec(\n",
    "            tokenized_tweet,\n",
    "            size=500, # output dimensions\n",
    "            window=5, # context window size\n",
    "            min_count=5, # ignore any words that appear less than 5 times.                                  \n",
    "            sg = 1, # skip-gram model\n",
    "            hs = 0,\n",
    "            negative = 10, # negative sampling\n",
    "            workers= 12, # number of cores that can be used\n",
    ") \n",
    "\n",
    "model_w2v.train(tokenized_tweet, total_examples= len(df['cleaned_tweet']), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hoe', 0.5057661533355713),\n",
       " ('nomo', 0.4338616728782654),\n",
       " ('gbe', 0.41555023193359375),\n",
       " ('nigga', 0.41324546933174133),\n",
       " ('jeezi', 0.4015903174877167),\n",
       " ('ainn', 0.40138646960258484),\n",
       " ('budah', 0.40049153566360474),\n",
       " ('yassss', 0.3972647786140442),\n",
       " ('blowin', 0.396241158246994),\n",
       " ('trippen', 0.3931485712528229)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar(positive='bitch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += model_w2v[word].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError:  # handling the case where the token is not in vocabulary\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44783, 500)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_arrays = np.zeros((len(tokenized_tweet), 500)) \n",
    "for i in range(len(tokenized_tweet)):\n",
    "    wordvec_arrays[i,:] = word_vector(tokenized_tweet[i], 500)\n",
    "wordvec_df = pd.DataFrame(wordvec_arrays)\n",
    "wordvec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.066181</td>\n",
       "      <td>-0.035399</td>\n",
       "      <td>-0.027133</td>\n",
       "      <td>-0.092303</td>\n",
       "      <td>0.018326</td>\n",
       "      <td>0.092508</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.042540</td>\n",
       "      <td>0.050757</td>\n",
       "      <td>0.029306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091189</td>\n",
       "      <td>-0.043999</td>\n",
       "      <td>-0.063556</td>\n",
       "      <td>0.029310</td>\n",
       "      <td>-0.009480</td>\n",
       "      <td>0.076450</td>\n",
       "      <td>-0.045681</td>\n",
       "      <td>-0.017032</td>\n",
       "      <td>-0.147821</td>\n",
       "      <td>0.098847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.094335</td>\n",
       "      <td>-0.028530</td>\n",
       "      <td>0.003487</td>\n",
       "      <td>-0.102002</td>\n",
       "      <td>0.147740</td>\n",
       "      <td>-0.029895</td>\n",
       "      <td>-0.117133</td>\n",
       "      <td>0.024006</td>\n",
       "      <td>0.118032</td>\n",
       "      <td>-0.051267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118761</td>\n",
       "      <td>0.032920</td>\n",
       "      <td>-0.036344</td>\n",
       "      <td>-0.128915</td>\n",
       "      <td>-0.177710</td>\n",
       "      <td>-0.006288</td>\n",
       "      <td>0.034197</td>\n",
       "      <td>-0.013182</td>\n",
       "      <td>-0.253888</td>\n",
       "      <td>0.067646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.103317</td>\n",
       "      <td>-0.234352</td>\n",
       "      <td>0.045708</td>\n",
       "      <td>-0.097701</td>\n",
       "      <td>0.041506</td>\n",
       "      <td>-0.005173</td>\n",
       "      <td>-0.026740</td>\n",
       "      <td>0.049248</td>\n",
       "      <td>0.081093</td>\n",
       "      <td>-0.008674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081975</td>\n",
       "      <td>-0.009049</td>\n",
       "      <td>0.058545</td>\n",
       "      <td>0.053516</td>\n",
       "      <td>-0.049780</td>\n",
       "      <td>0.012835</td>\n",
       "      <td>0.020336</td>\n",
       "      <td>-0.079465</td>\n",
       "      <td>-0.223279</td>\n",
       "      <td>0.142343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005340</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>0.015981</td>\n",
       "      <td>-0.049281</td>\n",
       "      <td>0.011348</td>\n",
       "      <td>-0.120900</td>\n",
       "      <td>-0.048288</td>\n",
       "      <td>0.067851</td>\n",
       "      <td>-0.022352</td>\n",
       "      <td>-0.096339</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016759</td>\n",
       "      <td>-0.094090</td>\n",
       "      <td>-0.014938</td>\n",
       "      <td>-0.151531</td>\n",
       "      <td>0.064355</td>\n",
       "      <td>0.034876</td>\n",
       "      <td>-0.030905</td>\n",
       "      <td>-0.045846</td>\n",
       "      <td>0.087639</td>\n",
       "      <td>0.051396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064984</td>\n",
       "      <td>-0.035206</td>\n",
       "      <td>-0.016940</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>-0.085344</td>\n",
       "      <td>0.015736</td>\n",
       "      <td>0.011379</td>\n",
       "      <td>0.003436</td>\n",
       "      <td>0.173896</td>\n",
       "      <td>-0.035595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130607</td>\n",
       "      <td>0.073325</td>\n",
       "      <td>-0.027066</td>\n",
       "      <td>0.090986</td>\n",
       "      <td>-0.011238</td>\n",
       "      <td>-0.047989</td>\n",
       "      <td>-0.004410</td>\n",
       "      <td>-0.091147</td>\n",
       "      <td>-0.240882</td>\n",
       "      <td>0.074197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.066181 -0.035399 -0.027133 -0.092303  0.018326  0.092508  0.039254   \n",
       "1  0.094335 -0.028530  0.003487 -0.102002  0.147740 -0.029895 -0.117133   \n",
       "2  0.103317 -0.234352  0.045708 -0.097701  0.041506 -0.005173 -0.026740   \n",
       "3  0.005340  0.027800  0.015981 -0.049281  0.011348 -0.120900 -0.048288   \n",
       "4  0.064984 -0.035206 -0.016940  0.024691 -0.085344  0.015736  0.011379   \n",
       "\n",
       "        7         8         9    ...       490       491       492       493  \\\n",
       "0  0.042540  0.050757  0.029306  ...  0.091189 -0.043999 -0.063556  0.029310   \n",
       "1  0.024006  0.118032 -0.051267  ...  0.118761  0.032920 -0.036344 -0.128915   \n",
       "2  0.049248  0.081093 -0.008674  ...  0.081975 -0.009049  0.058545  0.053516   \n",
       "3  0.067851 -0.022352 -0.096339  ... -0.016759 -0.094090 -0.014938 -0.151531   \n",
       "4  0.003436  0.173896 -0.035595  ...  0.130607  0.073325 -0.027066  0.090986   \n",
       "\n",
       "        494       495       496       497       498       499  \n",
       "0 -0.009480  0.076450 -0.045681 -0.017032 -0.147821  0.098847  \n",
       "1 -0.177710 -0.006288  0.034197 -0.013182 -0.253888  0.067646  \n",
       "2 -0.049780  0.012835  0.020336 -0.079465 -0.223279  0.142343  \n",
       "3  0.064355  0.034876 -0.030905 -0.045846  0.087639  0.051396  \n",
       "4 -0.011238 -0.047989 -0.004410 -0.091147 -0.240882  0.074197  \n",
       "\n",
       "[5 rows x 500 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tfidf_df\n",
    "y = df['is_offensive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logistic_regression.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.9092533047517"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "accuracy_percentage = 100 * accuracy\n",
    "accuracy_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9545364304149294"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = wordvec_df\n",
    "y = df['is_offensive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logistic_regression.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.97141836370132"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "accuracy_percentage = 100 * accuracy\n",
    "accuracy_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.944406043250716"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "for w in model_w2v.wv.vocab.keys():\n",
    "    embeddings_index[w] = model_w2v.wv[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['cleaned_tweet']\n",
    "y = df['is_offensive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=100000)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "sequences = tokenizer.texts_to_sequences(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "webdotwizard night the rushworth commun hous webdotwiz here earli\n",
      "your posit know bound reckon will want more than them torr will score least brace\n",
      "yey for wymt the concert wa ace last night\n",
      "welcom happi for dad too\n",
      "call mom\n"
     ]
    }
   ],
   "source": [
    "for x in x_train[:5]:\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9343, 85, 1, 9344, 1264, 241, 9345, 74, 377],\n",
       " [15, 800, 36, 2321, 3606, 55, 54, 72, 120, 64, 5368, 55, 1139, 376, 3607],\n",
       " [2779, 6, 9346, 1, 905, 20, 1805, 129, 85],\n",
       " [289, 102, 6, 451, 48],\n",
       " [80, 299]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = []\n",
    "for x in x_train:\n",
    "    length.append(len(x.split()))\n",
    "max(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 9343,\n",
       "          85,    1, 9344, 1264,  241, 9345,   74,  377],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,   15,  800,   36, 2321, 3606,   55,   54,\n",
       "          72,  120,   64, 5368,   55, 1139,  376, 3607],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 2779,\n",
       "           6, 9346,    1,  905,   20, 1805,  129,   85],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,  289,  102,    6,  451,   48],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,   80,  299]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_seq = pad_sequences(sequences, maxlen=30)\n",
    "x_train_seq[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
    "x_test_seq = pad_sequences(sequences_test, maxlen=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 100000\n",
    "embedding_matrix = np.zeros((num_words, 500))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(embedding_matrix[3] ,embeddings_index.get('bitch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33587 samples, validate on 11196 samples\n",
      "Epoch 1/5\n",
      " - 7s - loss: 0.1175 - accuracy: 0.9617 - val_loss: 0.1063 - val_accuracy: 0.9657\n",
      "Epoch 2/5\n",
      " - 7s - loss: 0.0799 - accuracy: 0.9736 - val_loss: 0.1063 - val_accuracy: 0.9661\n",
      "Epoch 3/5\n",
      " - 7s - loss: 0.0639 - accuracy: 0.9787 - val_loss: 0.1157 - val_accuracy: 0.9661\n",
      "Epoch 4/5\n",
      " - 7s - loss: 0.0475 - accuracy: 0.9841 - val_loss: 0.1385 - val_accuracy: 0.9663\n",
      "Epoch 5/5\n",
      " - 7s - loss: 0.0372 - accuracy: 0.9869 - val_loss: 0.1494 - val_accuracy: 0.9676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b3d3d39a08>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn = Sequential()\n",
    "e = Embedding(100000, 500, weights=[embedding_matrix], input_length=30, trainable=False)\n",
    "model_cnn.add(e)\n",
    "model_cnn.add(Conv1D(filters=150, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "model_cnn.add(GlobalMaxPooling1D())\n",
    "model_cnn.add(Dense(200, activation='relu'))\n",
    "model_cnn.add(BatchNormalization())\n",
    "model_cnn.add(Dense(1, activation='sigmoid'))\n",
    "model_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_cnn.fit(x_train_seq, y_train, validation_data=(x_test_seq, y_test), epochs=5,  verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_cnn.predict(x_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(y_pred)):\n",
    "    if (y_pred[i] >= 0.5) :\n",
    "        y_pred[i] = 1\n",
    "    else :\n",
    "        y_pred[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.7577706323687"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "accuracy_percentage = 100 * accuracy\n",
    "accuracy_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9650726450495525"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>is_offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp;amp; as a man you should always take the trash out...</td>\n",
       "      <td>woman you shouldnot complain about clean your hous man you should alway take the trash out</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!</td>\n",
       "      <td>boy dat cold tyga dwn bad for cuffin dat hoe the place</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit</td>\n",
       "      <td>dawg you ever fuck bitch and she start cri you confus shit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny</td>\n",
       "      <td>anderson base she look like tranni</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &amp;#57361;</td>\n",
       "      <td>the shit you hear about might true might faker than the bitch who told</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  \\\n",
       "0      2   \n",
       "1      1   \n",
       "2      1   \n",
       "3      1   \n",
       "4      1   \n",
       "\n",
       "                                                                                                                                          tweet  \\\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...   \n",
       "1                                                         !!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!   \n",
       "2                      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit   \n",
       "3                                                                                !!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny   \n",
       "4     !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;   \n",
       "\n",
       "                                                                                cleaned_tweet  \\\n",
       "0  woman you shouldnot complain about clean your hous man you should alway take the trash out   \n",
       "1                                      boy dat cold tyga dwn bad for cuffin dat hoe the place   \n",
       "2                                  dawg you ever fuck bitch and she start cri you confus shit   \n",
       "3                                                          anderson base she look like tranni   \n",
       "4                      the shit you hear about might true might faker than the bitch who told   \n",
       "\n",
       "   is_offensive  \n",
       "0             0  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    24163\n",
       "1    19190\n",
       "0     1430\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_hate_speech'] = 0\n",
    "df.loc[(df['class'] == 0),'is_hate_speech']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    19190\n",
       "0     1430\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = df[(df['class']==2)].index\n",
    "dfo = df.copy()\n",
    "dfo.drop(index, inplace = True)\n",
    "df = dfo\n",
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19190\n",
       "1     1430\n",
       "Name: is_hate_speech, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_hate_speech'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>is_offensive</th>\n",
       "      <th>is_hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!</td>\n",
       "      <td>boy dat cold tyga dwn bad for cuffin dat hoe the place</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit</td>\n",
       "      <td>dawg you ever fuck bitch and she start cri you confus shit</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny</td>\n",
       "      <td>anderson base she look like tranni</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &amp;#57361;</td>\n",
       "      <td>the shit you hear about might true might faker than the bitch who told</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just blows me..claim you so faithful and down for somebody but still fucking with hoes! &amp;#128514;&amp;#128514;&amp;#128514;\"</td>\n",
       "      <td>madison the shit just blow claim you faith and down for somebodi but still fuck with hoe</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  \\\n",
       "0      1   \n",
       "1      1   \n",
       "2      1   \n",
       "3      1   \n",
       "4      1   \n",
       "\n",
       "                                                                                                                                                            tweet  \\\n",
       "0                                                                           !!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!   \n",
       "1                                        !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit   \n",
       "2                                                                                                  !!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny   \n",
       "3                       !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;   \n",
       "4  !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just blows me..claim you so faithful and down for somebody but still fucking with hoes! &#128514;&#128514;&#128514;\"   \n",
       "\n",
       "                                                                              cleaned_tweet  \\\n",
       "0                                    boy dat cold tyga dwn bad for cuffin dat hoe the place   \n",
       "1                                dawg you ever fuck bitch and she start cri you confus shit   \n",
       "2                                                        anderson base she look like tranni   \n",
       "3                    the shit you hear about might true might faker than the bitch who told   \n",
       "4  madison the shit just blow claim you faith and down for somebodi but still fuck with hoe   \n",
       "\n",
       "   is_offensive  is_hate_speech  \n",
       "0             1               0  \n",
       "1             1               0  \n",
       "2             1               0  \n",
       "3             1               0  \n",
       "4             1               0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           [boy, dat, cold, tyga, dwn, bad, for, cuffin, dat, hoe, the, place]\n",
       "1                                       [dawg, you, ever, fuck, bitch, and, she, start, cri, you, confus, shit]\n",
       "2                                                                     [anderson, base, she, look, like, tranni]\n",
       "3                         [the, shit, you, hear, about, might, true, might, faker, than, the, bitch, who, told]\n",
       "4    [madison, the, shit, just, blow, claim, you, faith, and, down, for, somebodi, but, still, fuck, with, hoe]\n",
       "Name: cleaned_tweet, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tweet = df.cleaned_tweet.apply(lambda x: x.split())\n",
    "tokenized_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20620, 500)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=500, ngram_range=(1,3))\n",
    "tfidf_df = tfidf_vectorizer.fit_transform(df['cleaned_tweet'])\n",
    "tfidf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20620, 500)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_arrays = np.zeros((len(tokenized_tweet), 500)) \n",
    "for i in range(len(tokenized_tweet)):\n",
    "    wordvec_arrays[i,:] = word_vector(tokenized_tweet[i], 500)\n",
    "wordvec_df = pd.DataFrame(wordvec_arrays)\n",
    "wordvec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tfidf_df\n",
    "y = df['is_hate_speech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logistic_regression.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.03588748787584"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "accuracy_percentage = 100 * accuracy\n",
    "accuracy_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4318181818181818"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10951008645533142"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17471264367816094"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = wordvec_df\n",
    "y = df['is_hate_speech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logistic_regression.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.73423860329777"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "accuracy_percentage = 100 * accuracy\n",
    "accuracy_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6434782608695652"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20786516853932585"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31422505307855625"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['cleaned_tweet']\n",
    "y = df['is_hate_speech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=100000)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "sequences = tokenizer.texts_to_sequences(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = []\n",
    "for x in x_train:\n",
    "    length.append(len(x.split()))\n",
    "max(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_seq = pad_sequences(sequences, maxlen=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
    "x_test_seq = pad_sequences(sequences_test, maxlen=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15465 samples, validate on 5155 samples\n",
      "Epoch 1/5\n",
      " - 3s - loss: 0.2554 - accuracy: 0.9086 - val_loss: 0.2411 - val_accuracy: 0.9117\n",
      "Epoch 2/5\n",
      " - 3s - loss: 0.1537 - accuracy: 0.9448 - val_loss: 0.2244 - val_accuracy: 0.9292\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.1052 - accuracy: 0.9614 - val_loss: 0.2406 - val_accuracy: 0.9160\n",
      "Epoch 4/5\n",
      " - 3s - loss: 0.0656 - accuracy: 0.9762 - val_loss: 0.3873 - val_accuracy: 0.9311\n",
      "Epoch 5/5\n",
      " - 3s - loss: 0.0458 - accuracy: 0.9844 - val_loss: 0.3391 - val_accuracy: 0.8927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b3d66d3048>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn2 = Sequential()\n",
    "e = Embedding(100000, 500, weights=[embedding_matrix], input_length=30, trainable=False)\n",
    "model_cnn2.add(e)\n",
    "model_cnn2.add(Conv1D(filters=150, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "model_cnn2.add(GlobalMaxPooling1D())\n",
    "model_cnn2.add(Dense(200, activation='relu'))\n",
    "model_cnn2.add(BatchNormalization())\n",
    "model_cnn2.add(Dense(1, activation='sigmoid'))\n",
    "model_cnn2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_cnn2.fit(x_train_seq, y_train, validation_data=(x_test_seq, y_test), epochs=5,  verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_cnn2.predict(x_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(y_pred)):\n",
    "    if (y_pred[i] >= 0.5) :\n",
    "        y_pred[i] = 1\n",
    "    else :\n",
    "        y_pred[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.2725509214355"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "accuracy_percentage = 100 * accuracy\n",
    "accuracy_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3176043557168784"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4971590909090909"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3875968992248062"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
